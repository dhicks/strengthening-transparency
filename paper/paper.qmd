---
title: "The aims of science and an open science controversy at USEPA"
authors:
  - name: "D.J. Hicks"
    email: "dhicks4@ucmerced.edu"
    affiliations: 
      - id: a
        name: "University of California, Merced"
        city: "Merced"
        country: "CA, USA"
    orcid: "0000-0001-7945-4416"
    corresponding: true
  - name: "Emilio J. C. Lobato"
    affiliations:
      - ref: a
    orcid: "0000-0002-3066-2932"
  - name: "Cosmo Campbell"
    affiliations:
      - ref: a
  - name: "Joseph Dad"
    affiliations:
      - ref: a
  
abstract: "abstract"

acknowledgments: "acknowledgments"

bibliography: "st_text_mining.yaml"

format:
  html:
    toc: true
    number-sections: true
  aft-pdf:
    keep-tex: true
    link-citations: true
    mathspec: true
    fig.env: "figure*"
    include-in-header:
        - text: |
            \usepackage{pdflscape}
            \usepackage{framed}
    number-sections: true
    cite-method: citeproc

crossref:
  fig-prefix: ""
  tbl-prefix: ""

execute:
  eval: true
  echo: false
  warning: false
  message: false
---

<!-- 
PHOS submission guidelines: 
<https://www.cambridge.org/core/journals/philosophy-of-science/information/author-instructions>

Articles are limited to 9000 words, inclusive of abstract, footnotes, in-text citations, and appendices intended to appear with the manuscript.  Reference sections and online-only appendices are not included in the word count.


BJPS submission guidelines: 
<https://www.journals.uchicago.edu/journals/bjps/instruct> 

"strict 24 page limit," though not including references
-->

```{r}
library(readr)
library(gt)
library(here)

out_dir = here('out')
```

# Introduction

In this paper, we argue that the aims approach to values in science can provide a useful framework for identifying certain kinds of deep disagreements in public scientific controversies. Specifically, by applying text mining methods to a large collection of public comments on an open data rule at the US Environmental Protection Agency (USEPA), we argue that supporters and opponents of the rule exemplify the two rival views of the aims of science identified by Hicks [-@HicksScientificPracticesTheir2012; -@HicksWhenVirtuesAre2022]. 

## The aims approach

While not as influential as the argument from inductive risk *[Douglas, Havstad]*, the aims approach to values in science provides a distinct challenge to the value-free ideal. Proponents of the approach argue that science typically has not only epistemic aims but also practical or pragmatic ones, and that at any stage of inquiry decisions should be made so as to promote those aims. So, specifically, in the "core" of inquiry decisions should be made so as to promote pragmatic aims, and in this way non-epistemic values can play a legitimate role in the "core" of inquiry. *[cites]*  For example, *[Elliott and McKaughan]* argue that the pragmatic aim of quick and protective regulatory review in chemical safety testing supports using rapid screening techniques, which are much faster than other methods but will likely have a higher false positive rate. 

Note that this argument does not necessarily deny that science has epistemic aims, as may be done by approaches inspired by John Dewey *[Anderson; Brown]* or Donald Davidson *[Clough]*. This argument is also independent of questions about the definition of epistemic values or a sharp demarcation of values into "epistemic" vs. "social" *[Longino; Rooney; McMullin; Steel]*. Instead, the key assumption of this argument is that science does not have *only* epistemic aims. 

Proponents of the aims approach often argue for pluralism about aims of science *[Elliott and McKaughan; Potochnik]*, with *[Lusk and Elliott]* explicitly rejecting "the view
that science has global aims that constrain the influence of local aims on scientific
practice" (1). Both epistemic and pragmatic aims are often presented as specific to a discipline, field, or research program *[Tapestry ch. 4; examples]*. *[Intemann's]* early statement of the approach argues for "democratically endorsed" aims. *[more?]*

A distinctive aspect of *[Hicks']* version of the aims approach is an analysis of two general "views" of the aims of science, and a claim that an unrecognized disagreement between the two views is a recurrent feature of debates, not only among scientists and the public but also among philosophers.  For Hicks, the "broad view" corresponds to the aims approach argument sketched above — science has both epistemic and pragmatic aims — while the "narrow view" denies the "key assumption" of that argument, taking science to have only epistemic aims *[cites]*. On the narrow view, applications of scientific research are seen as happy accidents but not the primary function or purpose of research. Allowing pragmatic considerations (read: non-epistemic values) to influence inquiry is a corrupting influence, morally on a par with the epistemic distortions introduced by industrial funding *[Bennett and Holman; Fernandez Pinto]* or *[Wansink]*. 

Something like Hicks' two views appears in philosophical debates over the argument from inductive risk. *[acceptance vs. belief]*









## *Strengthening Transparency in Regulatory Science*

*Strengthening Transparency in Regulatory Science* (henceforth Strengthening Transparency or ST) was a rule proposed^[Technically, the rule was finalized and adopted in January 2021, just a few weeks before Trump's first administration ended. The rule was never enforced, and formally vacated in February 2021 by a federal judge on procedural grounds and without objection from the Biden administration. The final title of the rule was *Strengthening Transparency in Pivotal Science Underlying Significant Regulatory Actions and Influential Scientific Information*. For simplicity, I usually refer to it by the original title, and I characterize its effects counterfactually.] by USEPA during the first Trump administration [@USEPAStrengtheningTransparencyRegulatory2018; @USEPAStrengtheningTransparencyPivotal2021]. Strengthening Transparency would have imposed a strong open data and code requirement on any "regulatory science" utilized by USEPA to develop new regulations, generally prohibiting the agency from utilizing any research where the data and analysis code were not publicly available [@HicksWhenVirtuesAre2022; @HicksOpenScienceReplication2023]. 

At least in the initial public notice, proponents of Strengthening Transparency appealed to the open science movement and, specifically, open science as a necessary response to the "replication crisis," a purportedly widespread crisis in which influential and high-profile scientific results often could not be replicated [@USEPAStrengtheningTransparencyRegulatory2018 18769-70].  @HicksOpenScienceReplication2023 argued that, at the time ST was proposed, there was limited evidence that the replication crisis extended beyond a handful of scientific fields, and specifically there was no evidence that the crisis covered environmental epidemiology. 

Strengthening Transparency was the culmination of a campaign against "secret science" at USEPA. At least since the 1990s [@LernerRepublicansAreUsing2017], regulated industries have leveled complaints against certain highly influential environmental epidemiological studies [such as @DockeryAssociationAirPollution1993 and @RauhImpactPrenatalChlorpyrifos2006], alleging nonspecific data and analysis problems and demanding access to the "raw data" [@HicksWhenVirtuesAre2022 §2.2]. *[secret science act]*

Strengthening Transparency received a relatively high degree of mainstream news coverage [@HakimPesticideStudiesWon2018; @AchenbachScientistsDecryNew2018; @MufsonEPAExcludedTop2018; @FriedmanEPALimitScience2019; @DennisEPAPushesAhead2019] and was publicly opposed by a number of scientific organizations and environmental advocacy organizations *[cites]*.  Notably, some of the public opponents included prominent advocates of open science *[cites]*. Perhaps the most common argument against ST, as reported in news coverage or made by public figures, was that environmental epidemiological studies are often based on medical records and other sensitive information that legally cannot be made publicly available. Another common concern was that, if the rule was applied retroactively, for studies conducted decades ago the "raw data" might no longer exist [again, such as @DockeryAssociationAirPollution1993 and @RauhImpactPrenatalChlorpyrifos2006]. 



## Text mining

Text mining has emerged as a method for empirical philosophy of science over the past decade.  Broadly, text mining aims to identify patterns in the use of terms across a large collection of documents (called a *corpus*).  While initially developed by computer scientists, text mining methods have been widely adopted by both social scientists [@NelsonComputationalGroundedTheory2020; @StoltzMappingTextsComputational2024] and — under the umbrella of "digital humanities" — humanists [@UnderwoodDistantHorizonsDigital2019].  

One of the first applications of text mining to philosophy of science was an analysis of Charles Darwin's reading list [@MurdockExplorationExploitationVictorian2017], which used an information-theoretic measure of "surprise" to model Darwin's use of "exploration" and "exploitation" strategies in his reading.  Malaterre and collaborators have reflexively applied one prominent text mining method, topic modeling, to philosophy of science corpora — especially journal archives — to trace developments in the field over time [@MalaterreRevisitingThreeDecades2019; @MalaterreWhatThisThing2019; @MalaterreEightJournalsEight2020; @MalaterreEarlyDaysContemporary2022].  Their most recent work combines machine translation with topic modeling, expanding the scope of their analysis to incorporate multiple languages.  @HicksRaceScienceMainstream2024 use agnotology as a theoretical framework for a text mining analysis of race science in mainstream psychology. The text mining case studies in @DeBlockDynamicsScienceComputational2022 deploy a variety of methods, including named-entity recognition (NER) and network analysis [@PenceHowNotFight2022] and keyword search to facilitate deep reading [@GinammiBolzanoKantTraditional2022].  @VaesenPotentialSupervisedMachine2022 argues that supervised machine learning approach can incorporate philosophical expertise in ways that topic modeling cannot; we independently adopted a similar approach in part of the current study.  

Almost all of these examples of text mining in philosophy of science use, as their corpus, formal publications by scientists (or other scholars, such as philosophers).  Such corpora are not just apt — we often want to understand how scientists think about, or at least present, their research practices and findings — but also convenient — at least to those of us who have access to a university research library.  However, for understanding public scientific controversies, we are often more interested in how publics — various interested groups of people — understand science and its relationship to the controversy.  

We propose that public comments on high-profile governmental regulatory actions such as Strengthening Transparency can be apt and convenient corpora for understanding the publics involved in public scientific controversies.  In the United States, the Administrative Procedure Act requires federal government agencies to follow a "notice and comment" process before adopting new or modified regulations *[cite]*.  Agencies are required to publish a Notice of Proposed Rulemaking (NPR), including the draft text of the rule and background information to justify it, and then collect and respond to public comments before finalizing the rule.  Conveniently, most comments are made freely and publicly available on the website `regulations.gov`, which also includes a free API (application programming interface) to facilitate bulk downloads ("scraping").  High-profile proposed rules can collect large numbers of comments, from a variety of different groups and perspectives on the issue at hand in the rule, making it apt for understanding how different groups might, for instance, deploy different views of the aims of science.  

## Text mining ST: Primary findings and roadmap of the paper

Presumably due to the mainstream news coverage, ST had an exceptionally high profile, with nearly one million comments submitted and available on `regulations.gov`.^[In the text mining results below, the corpus contains "only" about 22,000 comments.  Regulations.gov distinguishes between "comments posted" and "comments received"; a single comment for the "posted" count can include multiple comments for the "received" count.  For example, the longest comments in the ST corpus comprise tens of thousands of signed electronic form letters.  This aggregation would count as one "posted" comment but tens of thousands of "received" comments.]  We use this substantial corpus to examine how supporters and opponents talk about science and health, finding that opponents talk about health and the environment about as often as they talk about science; while supporters talk exclusively about science, with a distinctive emphasis on a cynical or skeptical framing of the epistemic reliability of the science utilized by USEPA.  

We argue that these differences between opponents and supporters correspond to Hicks' [-@HicksWhenVirtuesAre2022] distinction between broad and narrow views of science. 

@sec-methods-overview gives a non-technical overview of our text mining methods; @sec-methods provides a more technical discussion, for readers who are familiar with text mining.  @sec-results reports the empirical results of the analysis. In @sec-discussion, we first argue that our empirical results can be fruitfully understood in terms of the two views of the aims of science.  We go on to suggest that, in the context of public discourse, deployment of philosophical ideas — such as views of the aims of science — might best be understood as somewhat opportunistic interpretive frames, rather than expressions of beliefs.  


# Methods overview {#sec-methods-overview}

We provide technical details on our methods in @sec-methods.  This section provides a non-technical overview. 

The US General Services Administration receives and publishes public comments on proposed rules using the website `regulations.gov` (<https://www.regulations.gov>).  Commenters may submit comments by online form, email, or physical mail, and electronic formats allow commenters to include a number of attachments.  Attachments are typically longer comments or journal articles, reports, etc., as supporting evidence.  

All agency-published documents and public comments associated with a proposed rule are collected together in a docket, e.g., EPA-HQ-OA-2018-0259 for Strengthening Transparency, available at <https://www.regulations.gov/docket/EPA-HQ-OA-2018-0259>.  [A1] collected all public comments from this docket in 2020 and 2021, with a final check several months after ST was finalized (in the last few weeks of the Trump administration) and vacated (a few weeks into the Biden administration).  

Initial, undirected exploration of the corpus in 2020-2021 by [A1] indicated that (a) there was a qualitatively clear division between supporters and opponents of ST, (b) commenters offered substantive reasons for their position on ST, (c) these reasons often connected science to public health, but (d) opposing comments were much, much more prevalent than supportive comments.  Example comments are given in figures @fig-opposed and @fig-support. 

::: {#fig-opposed}
\begin{framed}
\raggedright

Im writing to speak out AGAINST your proposed regulations to assault the EPAs use of science in the middle of a global public health crisis.

Peer-reviewed studies assessing the effects of pollution exposure on humans, based on actual personal health data which by law must be kept confidential are among the best science available to the Agency. The misguided proposal would direct EPA to ignore these data unless those confidential personal health data were made publicly available.

This is both unnecessary and impractical. As a retired scientist, I urge you to abandon this reckless plan, for the sake of our childrens health. To do otherwise is unconscionable.
\end{framed}

Example of an opposing comment on Strengthening Transparency. Original available at <https://www.regulations.gov/comment/EPA-HQ-OA-2018-0259-19410>. 
:::
::: {#fig-support}
\begin{framed}
\raggedright
I sincerely hope that you can distance the EPA agency from politically correct science. The only way to do this is to adopt the following methodology.

The scientific method demands that researchers' work be fully transparent.

Data must be made available for examination.

Theories must be open to challenge.

Disproven theories must be altered or set aside.

Barriers must be removed that would prevent valid conclusions from rising to the top.

I for one am tired of hearing about how bad technologies are for the planet, without any scientific proof that things today are different. Don't tell me that glarciers are melting and the ocean is rising a foot every 10 years. Remove yourselves from such statements and give facts about such a change: volume of water, how will it be measured, what could be causing it, what can be done that is both environmentally and economically sound.
\end{framed}

Example of a supporting comment on Strengthening Transparency. Original available at <https://www.regulations.gov/comment/EPA-HQ-OA-2018-0259-12305>.
:::

Point (a) meant that manual qualitative coding could be used to identify supporting and opposing comments; combined with points (b) and (c), this meant that the corpus was likely apt for contrasting the arguments given on either side of the ST controversy, and especially the way they connected (or not) epistemic and pragmatic aims.  But (d) meant that a simple random sample would include very few supporters, which would be suboptimal for using machine learning to automatically code the entire corpus.  @sec-sampling details the sampling procedure that we used for the manual coding step. 

We used a natural language processing (NLP) package for part-of-speech tagging, specifically identifying nouns and adjectives in the comment and attachment text.  (From this point forward, attachments were treated as continuations of comment text, and in what follows references to "comments" include the attachments.)  This let us construct adjective-noun bigrams, such as "public health" or "regulatory science."  Focusing on bigrams based on the nouns "health" and "science" let us greatly reduce the size of the vocabulary — the distinct terms used in a text mining analysis — which in turn greatly reduced the computation time necessary for any individual step.  [A1] had also identified the relationship between science and health, and its potential correspondence to the aims approach, as the central research question of the project.  Operationalized using science-health bigrams, this difference might show up in differences in noun frequency within or between sides (for example, opponents might use science bigrams more than supporters) or in different adjectives used with the same noun (for example, supporters might use different adjectives to describe health).  

[A1] had to set the project aside for a few years, but in January 2024 brought in the other authors.  Without informing the other authors of the research question, all authors independently coded each comment in the sample as supporting or opposing ST, or too ambiguous to classify.  Inter-rater reliability was good after one round of independent coding, and excellent after a round of discussion and separate review of discordant codes.  

Manual coding was limited to about 800 out of 22,000 comments.  We used a machine learning model to scale up the manual codes (supporting/opposing), using them as training data and imputing or predicting codes for the remaining comments.  To account for ambiguous comments (neither clearly supporting nor clearly opposing) and the possibility of error by the model, we conducted all analyses in parallel across three "codings": the *manual*ly-coded comments, the *imputed* codings for all 22k comments, and a *filtered* subset of the imputed codings, those where the model is at least 80% confident in its coding assignment.  

As we discuss below, it turned out that supporting comments were much less likely to use science-health bigrams than opposing comments, and so the bigram analysis omitted the majority of supporting comments.  We decided to cover the whole corpus using a keyword search.  But keyword searches are vulnerable to synonyms and actor-analyst conceptual mismatch.  We therefore used word embeddings, specific to this corpus, to identify potential synonyms and check conceptual alignment; see @sec-embeddings.  


# Results {#sec-results}

Table @tbl-n-docs shows the number of comments in the corpus, across the three coding methods and by support or opposition to ST; table @tbl-n-docs-1 shows counts for the whole corpus, while table @tbl-n-docs-2 shows counts for comments containing science or health bigrams.  In the whole corpus, opposing comments substantially outnumbered supporting comments, by a ratio of 3- or 4-to-1.  Also in the whole corpus, the ML classifier had a somewhat higher rate of supporting comments (~27%) than we identified with manual coding (19%).  In the filtered and imputed coding, most supporting comments did not use science or health bigrams.  

```{r}
#| eval: true
#| label: "tbl-n-docs"
#| tbl-cap: "Document counts, by coding method and opposition/support"
#| tbl-subcap:
#|   - "Whole corpus"
#|   - "Comments with science/health bigrams"
#| layout-ncol: 1
read_rds(here(out_dir, '09_n_docs.Rds'))
read_rds(here(out_dir, '09_n_docs_bigrams.Rds'))
```

In the manual coding, the 33 "neither" comments were almost all procedural requests to extend the public comment period, with a few comments discussing an issue that was mentioned as an example in the first NPR (the linear no-threshold model for radiation hazard) that we did not consider relevant to our analysis.  Because the ML classifier was not trained on these 33 "neither" comments, it forced all such comments into either the "support" or the "oppose" category.  Notably, the comments that were dropped by the "low confidence" filter (the "filtered" coding) are generally procedural requests to extend the public comment period.  


## Bigram analysis

Figure @fig-bigram-occurrence shows the 15 most common bigrams (both science and health) by ST support (rows of panels) across the three codings (columns of panels). Three bigrams occur in the majority of opposing comments, across all codings: "public health," "available science" (short for "best available science"), and "good science." Other common bigrams used by opponents include "human health," "environmental health," "reliable science," and "medical science."  

*[set blue L to like 40]*

![15 most common adjective-noun bigrams, by support for ST (rows of panels) and codings (columns of panels). Science bigrams in blue, health bigrams in red.  Relative document frequency is based only on comments containing science/health bigrams.](../out/09_occurrence.png){#fig-bigram-occurrence} 

Among supporting comments that use bigrams, they are less consistent in which bigrams they use:  no bigrams appear in the majority of comments.  The most common bigram is "secret science," followed by "regulatory science," "good science," and "public health"; though these three occur in fewer than 25% of comments.  

*[move most of this to discussion]*
There are also notable differences in the overall tone of the adjectives in supporters' and opponents' top bigrams.  Supporters seem to express skepticism or cynicism about the quality of scientific research: science is described as secret, secretive, phony, false, fake, shady, or deceptive.  In the context of these skeptical assessments, seemingly-positive valence bigrams — such as real, true, verifiable, and sound science — might be used as privatives, that is, expressing the idea that actually-existing science is *not* real, true, verifiable, or sound.  A skeptical or cynical assessment of science would provide support for ST insofar as open data would make science less secretive and phony and more verifiable and true, etc.  @HicksOpenScienceReplication2023 argued that there is no empirical evidence of a replication crisis in environmental epidemiology [though see @BagiletEstimatingSmallEffects *[cite as well in intro]*], and that ST's open data requirements would not mitigate widespread irreplicability even if it were a problem in that field. @HicksDevelopingMeasuresPublic2024 report preliminary evidence that cynicism is a better predictor of generalized trust in science than the value-free ideal. 

Table @tbl-noun-occ and figure @fig-noun-occ examine the occurrence of bigrams, aggregated by noun, for supporters and opponents.  For both supporters and opponents, almost all comments (~90% or more) that use bigrams use at least one science bigram.  For health bigrams and opponents, this is similar: almost all opponents use at least one health bigram.  But health bigrams are rare among supporters, with at most 26% of supportive comments (that use bigrams) using at least one health bigram.  

```{r}
#| eval: true
#| label: "tbl-noun-occ"
#| tbl-cap: "Bigram noun occurrence, by coding method and noun"
read_rds(here(out_dir, '09_noun_occ_tab.Rds'))
```

![Bigram noun occurrence, by coding method and noun, only comments containing science/health bigrams. Vertical lines connect the two nouns for a given coding and support.](../out/09_noun_occurrence.png){#fig-noun-occ}

This analysis indicates that supporters put much more emphasis on science than health in their comments on ST; while opponents emphasize science and health roughly equally. 

## Keyword analysis

The bigram analysis is limited to documents that contain adjective-noun bigrams, as identified by the NLP parser.  To expand this analysis, we switch to a keyword search of the entire corpus.  Table @tbl-keyword shows the occurrence of hits for five keyword searches, corresponding to science, health/medicine, the environment and ecology, business and the economy, and regulation. 

```{=latex}
\begin{landscape}
```
```{r}
#| eval: true
#| label: "tbl-keyword"
#| tbl-cap: "Keyword occurrence, by coding method and support. Footnotes indicate regular expressions used for search."
#| tbl-align: center
read_rds(here(out_dir, '11_keyword_tab.Rds'))
```
```{=latex}
\end{landscape}
```


In the bigram analysis, both supporters and opponents almost always used at least one science bigram.  This is still the case in the manually coding; but the rate is somewhat lower for supporters in the two imputed codings, ~65%.  Opponents are also likely to use health (~95%), environment (77% or more), and regulation (~70%) keywords.  By contrast, supporters are unlikely to use any keywords except science (and a slight majority for regulation keywords in the manual coding).  

We were surprised that supporters were unlikely to use business or regulation keywords, since we expected that they might support ST on the grounds that it would reduce regulation and thereby promote economic growth or business development.  To get a better sense of how supporters of ST were commenting, we calculated the log likelihood ratio for supporters and opponents for all (cleaned and lemmatized) unigram tokens in the corpus; see figure @fig-token-llr.  This use of log likelihood ratio identifies distinctive or characteristic terms, which have a relatively high likelihood of appearing on one side and a relatively low likelihood on the other. 

*[already using red/blue for health/science]*

![15 most distinctive terms (unigrams) for supporters and opponents, by coding. Terms in the top half are distinctive to opponents of ST; terms in the bottom half are distinctive to supporters.](../out/11_llr.png){#fig-token-llr} 

The magnitude of log likelihood ratios here reinforces the finding, from the bigram analysis, that supporters are less consistent in their language than opponents.  The most distinctive terms among supporters appear to correspond to the phrase "please stop/end/show your secret science," variations of which were common in the manual coding.  The tokens "regulation" (manual), "burdensome" (filtered, imputed), "regulate" (imputed), and "small" (all three) might correspond to concerns that burdensome regulations harm small businesses.  For opponents, the most distinctive term in all three codings is "health," and "protect" is second or third.  

These distinctive terms indicate not just what each side is saying about ST, but also what the other side is *not* saying.  Opponents do not deploy the "secret science" framing used by supporters, and supporters do not talk about USEPA's mission to protect human health and the environment. 


# Discussion {#sec-discussion}

## Two views of the aims of science

We argue that the results above can be fruitfully understood in terms of @HicksWhenVirtuesAre2022 account of two views of the aims of science.  Specifically, we claim that supporters deployed the narrow view, while opponents deployed the broad view.  

On the narrow view of supporters of ST, science has only epistemic aims.  The practical applications of science are at best irrelevant to the standards for good scientific research, and allowing such applications to shape things like data collection and analysis is comparable to — indeed, *is* — research misconduct.  The narrow view's exclusive focus on epistemic aims provides argumentative support for truth-promoting practices, such as those promoted by the open science movement, wherever it is feasible to do so.  Deployment of the narrow view explains why supporters said a great deal about science, but almost nothing about public health and the environment, and even very little about business and the economy.  All of these aspects of environmental policy are irrelevant to the standards for good scientific research. 

By contrast, opponents of ST deployed the broad view, on which science has both epistemic and practical aims.  Specifically, they appealed to the practical aims of protecting human health and the environment, raising concerns that ST's open data requirements would frustrate the pursuit of these aims, and was therefore "anti-science" [a primary goal of @HicksWhenVirtuesAre2022 is to develop a robust version of this argument].  In this way, the broad view provides an argumentative challenge to ST.  Deployment of the broad view explains why opponents talked about public health and the environment almost as frequently as science itself.  

Deployment of the broad view might also explain why opponents said relatively little about business and the economy.  On Hicks' analysis protecting human health and the environment are aims of environmental public health, but the impacts of regulation on the economy are still accidents, and thus irrelevant to the standards of good scientific research.  @HicksValuesDisclosuresTrust2022 provide survey evidence that, in the context of chemical regulation, members of the public — including political conservatives — put more trust in a scientist who discloses public health values than one who does not disclose values or discloses economic values. 

As an alternative to the aims approach, our findings might be interpreted in terms of inductive risk, and specifically differences between supporters and opponents in the relative importance of over- vs. under-regulation *[cites]*.  That is, supporters of ST might put more weight on over-regulation and preventable economic harms; while opponents of ST might put more weight on under-regulation and preventable disease and loss of life due to pollution.  

An inductive risk framing might work well for opponents, who are very likely to talk about public health, the environment, ecology, and other downstream social implications of ST.  But it does not seem to fit supporters, who talk about the economy about as often as they talk about the environment — that is, very little — and are less likely than not to talk about regulation.  We therefore take the aims approach to be a better fit for analyzing this particular controversy.  


## The views as interpretive frames, not beliefs

When we use text mining methods to study public comments like this, what are we studying? In particular, when we attribute one view of the aim of science to members of the public, are we saying that they *believe* this view, in anything like the way philosophers typically use that term? 

First, consider the many "form letter" comments. We labeled these comments in this way because we believe they were generated using an online form, which provided editable letter text and fields for a prospective commentator to enter their name, city and state, etc. These comments comprise 98% of the comments on Strengthening Transparency (counted granularly: 1 - 22k / 1M). While the text of these letters was editable, almost all prospective commentators made no changes. It is plausible that the vast majority of form letter commentators did not carefully read the letter they were "writing." 

Second, belief is often understood by philosophers as either a felt commitment to the truth of a claim or proposition, or as a behavioral disposition (with certain cognitive aspects) *[Schwitzgebel]*. In either conceptualization, beliefs are expected to be more-or-less stable across contexts (keeping fixed available evidence, belief in logically relevant claims, etc.). But there is circumstantial evidence^[By this we mean that the evidence below does not show that any identifiable individual endorsed different views of the aims of science in two different contexts. Instead our argument is that two incompatible views appear to be widely endorsed in the same group in different contexts, and thus it is highly probably that many individual members of this group have or would endorse both views in an unstable or logically inconsistent way.] that the views of aims of science we identified here are not stable. 

Consider opponents of ST, who we take to generally be environmentalists and political liberals or progressives ("liberals" for short). While liberals utilized the broad view in the ST controversy, in 2021 liberals also supported the development of scientific integrity plans across the Biden administration *[cites]*. The Biden administration's framework for these plans utilized the narrow view and the value-free ideal, portraying non-epistemic considerations exclusively as political interference or inappropriate influence (and without defining either of these terms):  

> Scientific findings and products must not be suppressed, delayed, or altered for political purposes and must not be subjected to inappropriate influence. 
> 
> Science, and public trust in science, thrives in an environment that shields scientific data and analyses and their use in policymaking from political interference or inappropriate influence. [@OSTPReleasesFramework2023 29-30]

On the other hand, as discussed above, we considered the possibility that supporters of ST — who we take to generally be political conservatives — appealed to pragmatic aims such as promoting economic growth, supporting small businesses, or reducing excessive regulation on industry. This would have amounted to utilizing the broad view, just with a different set of pragmatic aims from the liberal version. We found no evidence of a conservative broad view in the ST controversy; but of course conservatives appeal to such pragmatic aims in many other contexts *[cites]*. 

For these reasons, we do not interpret the comments on ST as expressing beliefs of the public on the aims of science. As an alternative, we suggest that the narrow and broad views can be understood as interpretive frames [@KleinDataFrameTheory2007]. Based on studies of the ways professionals make decisions in complex situations (primarily military intelligence analysts), @KleinDataFrameTheory2007 proposed that decisionmakers engage in "sensemaking," a form of inquiry [compare @BrownScienceMoralImagination2020 ch. 1] aimed at understanding rather than empirical accuracy [@KleinDataFrameTheory2007], and specifically understanding to support effective decisionmaking in the face of practical uncertainty. A "frame" is any "explanatory structure[] that account[s] for the data," including but not limited to stories, scripts, and maps [@KleinDataFrameTheory2007 120]. @KleinDataFrameTheory2007 emphasize that there is an iterative relationship between data and frame: "The data identify the relevant frame, and the frame determines which data are noticed. Neither of these comes first" [118; compare *[Hanson, Chang]*]. Because individuals operate with different "repertoires of frames," and data-gathering is informed by frames, "Different people viewing the same events can perceive and recall different things depending on their goals and experiences" [@KleinDataFrameTheory2007 121]. Extending this thought, we suggest that an individual's repertoire might include incompatible frames, and so similar events might be perceived and interpreted in very different ways by the same individual. 

Applied to the ST controversy, we suggest that both liberals and conservatives have both narrow and broad views of the aims of science among their repertoire of frames for interpreting public scientific controversies. But the frames were evoked differently in this particular controversy by being connected to two very different frames on the general trustworthiness of EPA/regulatory science *[McCright and Dunlap]*

While the degree of conservative distrust in science is often exaggerated *[cites]*, there is a large difference in partisan attitudes towards USEPA: @CerdaAmericansFeelFavorably2024 reports that only 32% of Republican/Lean Republican survey respondents have a favorable attitude towards USEPA, compared to 73% of Democratic/Lean Democratic respondents. Republican distrust of USEPA appears in the bigram analysis *[xref]*, in the *way* supporters talk about science, using adjectives such as *[list]*. These characterizations of science portray it as suffering from an inappropriate influence of non-epistemic values — specifically, politicization *[cite]*. The narrow view and the value-free ideal justify outrage at this situation, and by extension policies such as ST that are (believed to) mitigate these inappropriate influences. We further suggest that liberal utilization of the narrow view, in the context of scientific integrity plans, is also a response to politicization. 

More generally, the narrow view might be evoked or deployed when science is (perceived as) being influenced by *values one disagrees with*. This can be understood as what we might call a *depoliticization rhetorical strategy*, in two senses: first, as a call to mitigate the influence of politics; but second as an appeal to premises (epistemic values) that are taken to be uncontroversial and external to politics. In the second sense, depoliticization is a version of proxy politics [@HicksScientificControversiesProxy2017] or what Sarewitz calls the "scientization" of politics [@SarewitzHowScienceMakes2004], where political actors present political concerns and arguments as apolitical and purely scientific. 

*[broad view]*






Finally, reading the public comments as expressions of interpretive frames rather than beliefs can also help us understand what the "authors" of form letter comments were doing when they submitted a comment without modifying or even carefully reading the suggested text. For the low-stakes action of submitting a comment, details of argument and wording were less important than the general sentiment of the text — its vibes. So a few seconds to skim the suggested text would be sufficient for most commentators. 


# References 

::: {#refs}
:::


\appendix
\clearpage
\pagenumbering{arabic}
\renewcommand*{\thepage}{S\arabic{page}}
\renewcommand\thefigure{S\arabic{figure}}    
\setcounter{figure}{0} 
\renewcommand\thetable{S\arabic{table}}    
\setcounter{table}{0}
\renewcommand*{\thesection}{S\arabic{section}}

# Methods {#sec-methods}

{{< include methods.qmd >}}
